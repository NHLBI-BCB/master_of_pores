#!/usr/bin/env nextflow


/* 
 * Define the pipeline parameters
 *
 */

// Pipeline version
version = '0.1'

params.help            = false
params.resume          = false

log.info """

╔╦╗┌─┐┌─┐┌┬┐┌─┐┬─┐  ┌─┐┌─┐  ╔═╗╔═╗╦═╗╔═╗╔═╗
║║║├─┤└─┐ │ ├┤ ├┬┘  │ │├┤   ╠═╝║ ║╠╦╝║╣ ╚═╗
╩ ╩┴ ┴└─┘ ┴ └─┘┴└─  └─┘└    ╩  ╚═╝╩╚═╚═╝╚═╝
                                                                                       
====================================================
BIOCORE@CRG NanoTail. Detection of polyA length (RNA) - N F  ~  version ${version}
====================================================

*****************   Input files    *********************
folderin                : ${params.folderin}
comparison              : ${params.comparison}

******* reference has to be the transcriptome **********
reference                : ${params.reference}
output                   : ${params.output}

********* nanopolish and tailfindr cmd options **********
nanopolish_opt           : ${params.nanopolish_opt} 
tailfindr_opt            : ${params.tailfindr_opt} 

email                     : ${params.email}

"""

// Help and avoiding typos
if (params.help) exit 1
if (params.resume) exit 1, "Are you making the classical --resume typo? Be careful!!!! ;)"

// check input files
reference = file(params.reference)
if( !reference.exists() ) exit 1, "Missing reference file: ${reference}!"
config_report = file("$baseDir/config.yaml")
if( !config_report.exists() ) exit 1, "Missing config.yaml file!"
logo = file("$baseDir/../docs/logo_small.png")

nanopolish_opt 	   = params.nanopolish_opt
tailfindr_opt      = params.tailfindr_opt

// Output folders
outputTailfindr     = "${params.output}/Tailfindr"
outputNanoPolish    = "${params.output}/NanoPolish"
outputFinal         = "${params.output}/PolyA_final"

compfile = file(params.comparison)
if( !compfile.exists() ) exit 1, "Missing comparison file: ${compfile}. Specify path with --comparisons"

/*
 * Creates the channels with comparisons
 */
 Channel
    .from(compfile.readLines())
    .map { line ->
        list = line.split("\t")
        if (list[0]!= "") {
            sampleID = list[0]
            ctrlID = list[1]
            [ "${params.folderin}/${sampleID}", "${params.folderin}/${ctrlID}" ]
        }
    }
    .into{ ids_to_tailfindr; id_to_fetch_bam}

/*
 * Creates the channels that emits input data

Channel
    .fromFilePairs( params.folderin, type: 'dir', size: 1) 
    .ifEmpty { error "Cannot find any folder matching: ${params.folderin}" }
    .map {  
        sampleID = it[0]
        folderPath = it[1][0]
        fast5 = "${folderPath}/fast5_files/"
        fastq = "${folderPath}/fastq_files/"
        alignment = "${folderPath}/alignment/"
        [ sampleID, folderPath ]
    }.set{data_for_folders}

data_for_folders.cross(ids_to_compare).println()
 */

/*
 * Creates the channels that emits fast5 files
 
Channel
    .fromPath( params.fast5_sample)                                             
    .ifEmpty { error "Cannot find any sample file matching: ${params.fast5_sample}" }
    .set { fast5_sample_4_to_tail}

Channel
    .fromPath( params.fast5_control)                                             
    .ifEmpty { error "Cannot find any control file matching: ${params.fast5_control}" }
    .set { fast5_control_4_tail}

// Get the name from the folder
folder_sample_name = getFolderName(params.fast5_sample)
folder_ctrl_name = getFolderName(params.fast5_control)

// Get the channel for tail finder
//data_sample_4_tails = tailFindrChannel(fast5_sample_4_to_tail, tailfinder, params.bam_sample, params.fastq_sample)
//data_ctrl_4_tails = tailFindrChannel(fast5_control_4_tail, tailfinder, params.bam_control, params.fastq_control)

data_sample_4_tails.mix(data_ctrl_4_tails).into{
	data_4_tailfindr; data_4_nanopolish
}

/*
* Estimate polyA tail size
*/

process tailfindr {
	publishDir outputPolyA, pattern: "*_findr.csv",  mode: 'copy'
	tag { folder_name }  
	label 'big_mem_cpus'
	
	input:
	file(reference)
	set file(sample_fid), file(control_fid) from ids_to_tailfindr

	output:
	file("${folder_name}_findr.csv")

	script:
	"""
	R --slave -e "library(tailfindr); find_tails(fast5_dir = './' , save_dir = 'output', ${params.tailfinder}, csv_filename = \'${folder_name}_findr.csv\', num_cores = ${task.cpus})"
	"""
}

process tail_nanopolish {
	publishDir outputPolyA, pattern: "*.polya.estimation.tsv",  mode: 'copy'
	tag { folder_name }  
	label 'big_mem_cpus'
	
	input:
	file(reference)
	set folder_name, file(bam_file), file(fastq_file), file(fast5_files) from data_4_nanopolish

	output:
	file("${folder_name}.polya.estimation.tsv")

	script:
	def reference_cmd = unzipBash(reference)
	"""
	#index bam
	samtools index ${bam_file}
	#index reads
	nanopolish index -d ./ ${fastq_file}
	# polya length estimation
	nanopolish polya -r ${fastq_file} ${params.tailfinder} -g ${reference_cmd} -t ${task.cpus} -b ${bam_file} > ${folder_name}.polya.estimation.tsv
	"""
} 

/*
* functions
*/
// Get the name from the folder
def getFolderName(sample) {
   folder_info = sample.toString().tokenize("/")
   return folder_info[-2]
}

def tailFindrChannel(fast5s, tailfinder, bamfile, fastqfile) {
    fast5_4_tailfindr =Channel.empty()
    if (tailfinder == "nanopolish") {
	    fast5s.map { 
			[getFolderName(it), it]
		}.groupTuple().map { 
		[it[0], file(bamfile), file(fastqfile), it[1]]
		}.set{ fast5_4_tailfindr}
	} else {
	    fast5s.map { 
			[getFolderName(it), it]
		}.groupTuple().set{ fast5_4_tailfindr}		
	}
	return fast5_4_tailfindr
}

// make named pipe 
def unzipBash(filename) { 
    cmd = filename.toString()
    if (cmd[-3..-1] == ".gz") {
    	cmd = "<(zcat ${filename})"
    }
    return cmd
}

/*
*  Finish message
*/
workflow.onComplete {
    println "Pipeline completed at: $workflow.complete"
    println "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
}

/*
 * Mail notification


workflow.onComplete {
    def subject = 'Master of Pore execution'
    def recipient = "${params.email}"
    def attachment = "${outputMultiQC}/multiqc_report.html"

    ['mail', '-s', subject, '-a', attachment, recipient].execute() << """
    Pipeline execution summary
    ---------------------------
    Completed at: ${workflow.complete}
    Duration    : ${workflow.duration}
    Success     : ${workflow.success}
    workDir     : ${workflow.workDir}
    exit status : ${workflow.exitStatus}
    Error report: ${workflow.errorReport ?: '-'}
    """
}
*/